def warn(*args, **kwargs):
    pass
import warnings
warnings.warn = warn

from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import cross_val_score
from sklearn.svm import SVC
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from matplotlib import pyplot
from numpy import mean, std
from sklearn.decomposition import PCA  
from sklearn.model_selection import cross_validate
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA
from sklearn.ensemble import StackingClassifier

# Getting the dataset

url_train = 'https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tra'
url_test = 'https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.tes'
dataset_train = pd.read_csv(url_train, names= list(range(1, 66)))
dataset_test = pd.read_csv(url_test, names= list(range(1, 66)))

# Splitting the dataset to disjoint the Class property

X_tra = dataset_train.iloc[:, :-1].values
y_tra = dataset_train.iloc[:, -1].values

X_tes = dataset_test.iloc[:, :-1].values
y_tes = dataset_test.iloc[:, -1].values

# The function of the models

def get_models():
	estimators = [
    ('NB', GaussianNB()), 
    ('KNN', KNeighborsClassifier(n_neighbors=5)),
		('DT_gini', DecisionTreeClassifier(criterion= 'gini')),
    ]

	models = dict()
	models['knn1'] = KNeighborsClassifier(n_neighbors= 1)
	models['knn3'] = KNeighborsClassifier(n_neighbors= 3)
	models['knn5'] = KNeighborsClassifier(n_neighbors= 5)
	models['DT_entropy'] = DecisionTreeClassifier(criterion= 'entropy')
	models['DT_gini'] = DecisionTreeClassifier(criterion= 'gini')
	models['SVM_poly'] = SVC(kernel= 'poly')
	models['SVM_rbf'] = SVC(kernel= 'rbf')
	models['SVM_sigmoid'] = SVC(kernel= 'sigmoid')
	models['NB'] = GaussianNB()
	models['Ensemble'] = StackingClassifier(estimators= estimators, final_estimator= SVC(kernel= 'poly'))  
	return models

# The cross-validation function

def evaluate_model(model, X_train, y_train):
	scoring = ['precision_micro', 'recall_micro', 'accuracy', 'f1_micro']
	cv = RepeatedStratifiedKFold(n_splits=3, n_repeats=1, random_state=1)
	scores = cross_validate(model, X_train, y_train, scoring=scoring, cv=cv)
	return scores

# Executining the model

# define dataset
X, y = X_tra, y_tra

# get the models to evaluate
models = get_models()

# Dictionaries for storing results
time = {}
pre = {}
re = {}
f1 = {}
acc = []
names = []
mean_f1 = {}
std_f1  = {}
mean_accuracy = {}
std_accuracy  = {}
mean_precision = {}
std_precision  = {}
mean_recall = {}
std_recall  = {}

 
# evaluate the models and store results
results, names = list(), list()
for name, model in models.items():
	scores = evaluate_model(model, X, y)
	results.append(scores)
	names.append(name)
	mean_accuracy[name] = scores['test_accuracy'].mean()
	std_accuracy[name] = scores['test_accuracy'].std()
	mean_precision[name] = scores['test_precision_micro'].mean()
	std_precision[name] = scores['test_precision_micro'].std()
	mean_recall[name] = scores['test_recall_micro'].mean()
	std_recall[name] = scores['test_recall_micro'].std()
	mean_f1[name] = scores['test_f1_micro'].mean()
	std_f1[name] = scores['test_f1_micro'].std()
	time[name] = scores['score_time'].mean()
	pre[name] = scores['test_precision_micro']
	re[name] = scores['test_recall_micro']
	f1 = scores['test_f1_micro']
	acc.append(scores['test_accuracy'].mean())
	if name not in names :
		names.append(name)

# Printing the results
	if name == 'Ensemble':
		print(f'mean accuracy = {mean_accuracy}')
		print(f'std accuracy = {std_accuracy}')
		print('''
		''')
		print(f'mean precision = {mean_precision}')
		print(f'std precision = {std_precision}')
		print('''
		''')
		print(f'mean recall = {mean_recall}')
		print(f'std recall = {std_recall}')
		print('''
		''')
		print(f'mean f1 = {mean_f1}')
		print(f'std f1 = {std_f1}')
		print('''
		''')
		print(f'time = {time}')

# Plotting accuracy of different models

fig = plt.figure()
ax = fig.add_axes([0,0,1.7,1])
names = names
accuracy = acc
ax.bar(names,accuracy)
plt.show()

#plotting the correlation between recall and precision

fig, ax = plt.subplots()
ax.plot(pre[name],re[name], color='purple')

#add axis labels to plot
ax.set_title('Precision-Recall Curve')
ax.set_ylabel('Precision')
ax.set_xlabel('Recall')

#display plot
plt.show()

**PCA Dimensionality Reduction**

# Setting up PCA

pca = PCA()
X = pd.DataFrame(pca.fit_transform(X))

# Setting up the Ensemble algorithm

# define dataset
X, y = X_tra, y_tra

# get the models to evaluate
models = get_models()

pre = {}
re = {}
f1 = {}
acc = []
name = []
mean_f1 = {}
std_f1  = {}
mean_accuracy = {}
std_accuracy  = {}
mean_precision = {}
std_precision  = {}
mean_recall = {}
std_recall  = {}

# evaluate the models and store results
results, names = list(), list()
for name, model in models.items():
	scores = evaluate_model(model, X, y)
	results.append(scores)
	names.append(name)
	mean_accuracy[name]  = scores['test_accuracy'].mean()
	std_accuracy[name]   = scores['test_accuracy'].std()
	mean_precision[name] = scores['test_precision_micro'].mean()
	std_precision[name]  = scores['test_precision_micro'].std()
	mean_recall[name]    = scores['test_recall_micro'].mean()
	std_recall[name]     = scores['test_recall_micro'].std()
	mean_f1[name]        = scores['test_f1_micro'].mean()
	std_f1[name]         = scores['test_f1_micro'].std()
	pre[name] = scores['test_precision_micro']
	re[name] = scores['test_recall_micro']
	f1 = scores['test_f1_micro']
	acc.append(scores['test_accuracy'].mean())
	if name not in names :
		names.append(name)
	
# Printing the results
	if name == 'Ensemble':
		print(f'mean accuracy = {mean_accuracy}')
		print(f'std accuracy = {std_accuracy}')
		print('''
		''')
		print(f'mean precision = {mean_precision}')
		print(f'std precision = {std_precision}')
		print('''
		''')
		print(f'mean recall = {mean_recall}')
		print(f'std recall = {std_recall}')
		print('''
		''')
		print(f'mean f1 = {mean_f1}')
		print(f'std f1 = {std_f1}')
		print('''
		''')
		print(f'time = {time}')

# Plotting accuracy of different models

fig = plt.figure()
ax = fig.add_axes([0,0,1.7,1])
names = names
accuracy = acc
ax.bar(names,accuracy)
plt.show()

#plotting the correlation between recall and precision

fig, ax = plt.subplots()
ax.plot(pre[name],re[name], color='purple')

#add axis labels to plot
ax.set_title('Precision-Recall Curve')
ax.set_ylabel('Precision')
ax.set_xlabel('Recall')

#display plot
plt.show()

**LDA Dimensionality Reduction**

# Setting up LDA

lda = LDA(n_components=4)
X_train = lda.fit_transform(X_tra, y_tra)
X_test = lda.transform(X_tes)

# Setting up the Ensemble algorithm

# define dataset
X, y = X_tra, y_tra

# get the models to evaluate
models = get_models()

pre = {}
re = {}
f1 = {}
acc = []
name = []
mean_f1 = {}
std_f1  = {}
mean_accuracy = {}
std_accuracy  = {}
mean_precision = {}
std_precision  = {}
mean_recall = {}
std_recall  = {}

# evaluate the models and store results
results, names = list(), list()
for name, model in models.items():
	scores = evaluate_model(model, X, y)
	results.append(scores)
	names.append(name)
	mean_accuracy[name]  = scores['test_accuracy'].mean()
	std_accuracy[name]   = scores['test_accuracy'].std()
	mean_precision[name] = scores['test_precision_micro'].mean()
	std_precision[name]  = scores['test_precision_micro'].std()
	mean_recall[name]    = scores['test_recall_micro'].mean()
	std_recall[name]     = scores['test_recall_micro'].std()
	mean_f1[name]        = scores['test_f1_micro'].mean()
	std_f1[name]         = scores['test_f1_micro'].std()
	pre[name] = scores['test_precision_micro']
	re[name] = scores['test_recall_micro']
	f1 = scores['test_f1_micro']
	acc.append(scores['test_accuracy'].mean())
	if name not in names :
		names.append(name)
	
# Printing the results
	if name == 'Ensemble':
		print(f'mean accuracy = {mean_accuracy}')
		print(f'std accuracy = {std_accuracy}')
		print('''
		''')
		print(f'mean precision = {mean_precision}')
		print(f'std precision = {std_precision}')
		print('''
		''')
		print(f'mean recall = {mean_recall}')
		print(f'std recall = {std_recall}')
		print('''
		''')
		print(f'mean f1 = {mean_f1}')
		print(f'std f1 = {std_f1}')
		print('''
		''')
		print(f'time = {time}')

# Plotting accuracy of different models

fig = plt.figure()
ax = fig.add_axes([0,0,1.7,1])
names = names
accuracy = acc
ax.bar(names,accuracy)
plt.show()

#plotting the correlation between recall and precision

fig, ax = plt.subplots()
ax.plot(pre[name],re[name], color='purple')

#add axis labels to plot
ax.set_title('Precision-Recall Curve')
ax.set_ylabel('Precision')
ax.set_xlabel('Recall')

#display plot
plt.show()
